from langchain_chroma import Chroma
from langchain_ollama import OllamaEmbeddings

class VectorStoreWrapper:
    def __init__(self, config):
        self.config = config
        self.vector_store = None
        
        self.persist_directory = config.get("vector_db_path", "./rfp_database_bge")
        self.embedding_model_name = config.get("embedding_model", "bge-m3")

    def initialize(self):
        print(f"ğŸ“‚ DB ë¡œë”© ì‹œì‘: {self.persist_directory} (Model: {self.embedding_model_name})")
        
        # ë™ì ìœ¼ë¡œ ëª¨ë¸ëª… í• ë‹¹
        self.embedding = OllamaEmbeddings(model=self.embedding_model_name)
        
        self.vector_store = Chroma(
            persist_directory=self.persist_directory,
            embedding_function=self.embedding
        )
        print("âœ… DB ë¡œë”© ì™„ë£Œ!")

    def get_all_documents(self):
        if not self.vector_store:
            return []
        # ë©”íƒ€ë°ì´í„°ì—ì„œ sourceë§Œ ì¶”ì¶œí•´ì„œ ì¤‘ë³µ ì œê±° í›„ ë°˜í™˜
        data = self.vector_store.get()
        sources = set([meta.get('source').split('/')[-1] for meta in data['metadatas']])
        return list(sources)
