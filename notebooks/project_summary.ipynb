{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# RAG ChatBot Project Summary\n",
                "\n",
                "ì´ ë…¸íŠ¸ë¶ì€ í”„ë¡œì íŠ¸ì˜ **í•µì‹¬ ê¸°ëŠ¥(ê²€ìƒ‰ ë° ìƒì„± í”„ë¡œì„¸ìŠ¤)**ì„ ìš”ì•½í•˜ì—¬ ë¹ ë¥´ê²Œ í™•ì¸í•˜ê¸° ìœ„í•´ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
                "ë³µì¡í•œ ì›¹ UI(`app.py`)ë¥¼ ì‹¤í–‰í•˜ì§€ ì•Šê³  ë¡œì§ì´ ì˜ ë™ì‘í•˜ëŠ”ì§€ ê²€ì¦í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "\n",
                "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€\n",
                "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
                "\n",
                "from src.common.config import config\n",
                "from src.generation.rag import RAGChain\n",
                "from src.indexing.vector_store import VectorStoreWrapper"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
                "ì„¤ì •ì„ ë¡œë“œí•˜ê³  Vector DBì™€ RAG ì²´ì¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"ğŸ”¹ Loading Configuration: {config['model']['llm_name']}\")\n",
                "\n",
                "# Vector Store Load\n",
                "vector_store = VectorStoreWrapper(config)\n",
                "vector_store.initialize()\n",
                "\n",
                "# RAG Chain Load\n",
                "rag_chain = RAGChain(config=config, vector_store_wrapper=vector_store)\n",
                "\n",
                "print(\"âœ… System Initialized Successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. ë¬¸ì„œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (High Quality vs Fast Mode)\n",
                "Hybrid Searchì™€ Re-rankingì´ ì ìš©ëœ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "query = \"ì´ ì‚¬ì—…ì˜ ì˜ˆì‚°ì€ ì–¼ë§ˆì¸ê°€ìš”?\"\n",
                "\n",
                "# 1. ì¼ë°˜ ëª¨ë“œ (Re-ranking ì ìš©, ì •í™•ë„ ë†’ìŒ)\n",
                "print(f\"\\nğŸ” Query: {query}\")\n",
                "print(\"\\n--- [Standard Mode] (High Accuracy) ---\")\n",
                "standard_retriever = rag_chain.get_retriever(fast_mode=False)\n",
                "docs_standard = standard_retriever.invoke(query)\n",
                "for i, doc in enumerate(docs_standard):\n",
                "    print(f\"[{i+1}] {doc.page_content[:100]}... (Source: {doc.metadata.get('source', 'Unknown')})\")\n",
                "\n",
                "# 2. ê³ ì† ëª¨ë“œ (Re-ranking ë¯¸ì ìš©, ì†ë„ ë¹ ë¦„)\n",
                "print(\"\\n--- [Fast Mode] (High Speed) ---\")\n",
                "fast_retriever = rag_chain.get_retriever(fast_mode=True)\n",
                "docs_fast = fast_retriever.invoke(query)\n",
                "for i, doc in enumerate(docs_fast):\n",
                "    print(f\"[{i+1}] {doc.page_content[:100]}... (Source: {doc.metadata.get('source', 'Unknown')})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. ë‹µë³€ ìƒì„± í…ŒìŠ¤íŠ¸\n",
                "`stream_answer` ë©”ì„œë“œë¥¼ í†µí•´ í† í° ë‹¨ìœ„ë¡œ ìƒì„±ë˜ëŠ” ë‹µë³€ì„ ì‹œë®¬ë ˆì´ì…˜í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nğŸ¤– Generating Answer (Streaming)...\\n\")\n",
                "\n",
                "# ë‹µë³€ ìƒì„±\n",
                "stream = rag_chain.stream_answer(query, docs_standard, level=\"ìš”ì•½\")\n",
                "\n",
                "full_response = \"\"\n",
                "for chunk in stream:\n",
                "    print(chunk, end=\"\", flush=True)\n",
                "    full_response += chunk\n",
                "\n",
                "print(\"\\n\\nâœ… Generation Complete!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}